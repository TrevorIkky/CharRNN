{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CharRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4XQzaKrvlzVQcl43GrbFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrevorIkky/CharRNN/blob/main/CharRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeYAlcr_zcqQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IXCEntvSAVd"
      },
      "source": [
        "class StopCallback(keras.callbacks.Callback):\n",
        "  \"\"\"\n",
        "  Metrics should be similar to what was defined in the model.compile method\n",
        "  therefore the condition on on_epoch_end can change depending on the metrics\n",
        "  \"\"\"\n",
        "  def __init__(self, metrics=0.97):\n",
        "    super(StopCallback, self).__init__()\n",
        "    self.metrics = metrics\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if logs.get('acc') >= self.metrics:\n",
        "      print('Stopping model with {} accuracy'.format(logs.get('acc')))\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VIoxg8wWBZD"
      },
      "source": [
        "class ResetStateCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    self.model.reset_states = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zf64IN8Oqjt"
      },
      "source": [
        "class CharRNN:\n",
        "  def __init__(self, url, accuracy_threshold=0.97):\n",
        "    self.batch_size = 32\n",
        "    self.window_size = 100 + 1\n",
        "    self.accuracy_threshold = accuracy_threshold\n",
        "    path = keras.utils.get_file(\"shakespear.txt\", url)\n",
        "    with open(path) as f:\n",
        "      shakespear_text = f.read()\n",
        "    tokenizer = Tokenizer(char_level=True, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts([shakespear_text])\n",
        "    char_indices = tokenizer.word_index\n",
        "    char_count = tokenizer.document_count\n",
        "    [encoded] = np.array(tokenizer.texts_to_sequences([shakespear_text])) - 1\n",
        "    train_size = len(encoded) * 80 // 100\n",
        "    self.depth=len(char_indices)\n",
        "    self.train = self.seq2seq_windows(encoded[:train_size], self.depth, self.window_size, self.batch_size)\n",
        "   \n",
        "  def seq2seq_windows(self, encoded_chars, max_depth, window_size=32, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(encoded_chars)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    ds = ds.map(lambda X, Y: (tf.one_hot(X, max_depth), Y))\n",
        "    return ds.shuffle(1000).batch(batch_size).prefetch(1)\n",
        "\n",
        "  def seq2seq_windows_fstateful(self, encoded_chars, max_depth, window_size=32, batch_size=32):\n",
        "    #TODO: \n",
        "    pass\n",
        "\n",
        "  def compile_stateful_model(self):\n",
        "    #TODO make a stateful RNN that preserves the RNN's state between each iteration\n",
        "    pass\n",
        "\n",
        "  def compile_model(self):\n",
        "    self.model = keras.models.Sequential([\n",
        "      keras.layers.GRU(100, return_sequences=True, \n",
        "                       dropout=0.2, input_shape=[None, self.depth], \n",
        "                       recurrent_dropout=0.3),\n",
        "      keras.layers.GRU(100, return_sequences=True, \n",
        "                       dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.TimeDistributed(keras.layers.Dense(self.depth, activation=\"softmax\"))\n",
        "      ])\n",
        "    self.model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), \n",
        "              optimizer=keras.optimizers.Adam(), metrics=[\"acc\"])\n",
        "  def fit(self, accuracy):\n",
        "    early_stopping=keras.callbacks.EarlyStopping(patience=4)\n",
        "    lr_scheduler = keras.callbacks.LearningRateScheduler(lambda e: 1e-6 * 10**(e / 30))\n",
        "    acc_stopping = StopCallback(accuracy)\n",
        "    self.history = self.model.fit(self.train, epochs=1000, callbacks=[acc_stopping, early_stopping])\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    [encoded_text] = np.array(tokenizer.text_to_sequences([text])) - 1\n",
        "    return tf.one_hot(encoded_text, depth)\n",
        "  \n",
        "  def predict(self, text):\n",
        "    x = preprocess_text(text)\n",
        "    x_classes = self.history.predict_classes(x)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(x_classes)\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_text(char_id.numpy())[0]\n",
        "        \n",
        "  def build_text(self, text, n_chars=40):\n",
        "    for _ in range(n_chars):\n",
        "      text += predict(text)\n",
        "    return text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDsfh3tVRAaZ"
      },
      "source": [
        "shakespear_url = \"http://homl.info/shakespeare\"\n",
        "ch_rnn = CharRNN(shakespear_url, 0.98)\n",
        "ch_rnn.compile_model()\n",
        "#ch_rnn.fit(0.98)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}